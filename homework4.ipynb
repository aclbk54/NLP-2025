{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wlu-s2k9D1Ba"
   },
   "source": [
    "# Week 4: Transfer Learning, BERT (Homework)\n",
    "\n",
    "## Question Search Engine\n",
    "\n",
    "Embeddings are a good source of information for solving various tasks. For example, we can classify texts or find similar documents using their representations. We already know about word2vec, GloVe and fasttext, but they don't use context information from given text (only from contexts of source data).\n",
    "\n",
    "For today we will use full power of context-aware embeddings to find text duplicates!\n",
    "\n",
    "__Warning:__ this task assumes you have seen `seminar.ipynb`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HYffoHiI8du5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Glak\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfSHyQlT-fVF"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y2_wgtrx8e6C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample[0]: {'text1': 'How is the life of a math student? Could you describe your own experiences?', 'text2': 'Which level of prepration is enough for the exam jlpt5?', 'label': 0, 'idx': 0, 'label_text': 'not duplicate'}\n",
      "Sample[3]: {'text1': 'What can one do after MBBS?', 'text2': 'What do i do after my MBBS ?', 'label': 1, 'idx': 3, 'label_text': 'duplicate'}\n"
     ]
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": \"train.jsonl\",\n",
    "    \"validation\": \"validation.jsonl\",\n",
    "    \"test\": \"test.jsonl\"\n",
    "}\n",
    "\n",
    "qqp = datasets.load_dataset(\"json\", data_files=data_files)\n",
    "print(\"\\n\")\n",
    "print(\"Sample[0]:\", qqp[\"train\"][0])\n",
    "print(\"Sample[3]:\", qqp[\"train\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pStlWcvD8rdk"
   },
   "outputs": [],
   "source": [
    "model_name = \"./model\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qtkllSPG9bTL"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    result = tokenizer(\n",
    "        examples[\"text1\"],\n",
    "        examples[\"text2\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    result[\"label\"] = examples[\"label\"]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3HdPHQe4RmWs"
   },
   "outputs": [],
   "source": [
    "qqp_preprocessed = qqp.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ObMcFN59_Ll2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1293, 1110, 1103, 1297, 1104, 170, 12523, 2377, 136, 1180, 1128, 5594, 1240, 1319, 5758, 136,  ...\n"
     ]
    }
   ],
   "source": [
    "print(repr(qqp_preprocessed[\"train\"][0][\"input_ids\"])[:100], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyQ1ZbzGAUF2"
   },
   "source": [
    "### Evaluation (1 point)\n",
    "\n",
    "We randomly chose a model trained on QQP - but is it any good?\n",
    "\n",
    "One way to measure this is with validation accuracy - which is what you will implement next.\n",
    "\n",
    "Here's the interface to help you do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M5ueSoieAbBg"
   },
   "outputs": [],
   "source": [
    "val_set = qqp_preprocessed[\"validation\"]\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set, \n",
    "    batch_size=32,\n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    collate_fn=transformers.default_data_collator,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SsPwXXx-At-i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch: {'labels': tensor([0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0]), 'idx': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]), 'input_ids': tensor([[ 101, 1725, 1132,  ...,    0,    0,    0],\n",
      "        [ 101,  178, 1328,  ...,    0,    0,    0],\n",
      "        [ 101, 1110, 1175,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  107, 1150,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 2146,  ...,    0,    0,    0],\n",
      "        [ 101, 1725, 1674,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "\n",
      "Prediction (probs): [[6.5834200e-01 3.4165803e-01]\n",
      " [9.9996519e-01 3.4800854e-05]\n",
      " [9.8360768e-03 9.9016386e-01]\n",
      " [9.9996877e-01 3.1187868e-05]\n",
      " [9.9910480e-01 8.9513185e-04]\n",
      " [4.6791746e-03 9.9532086e-01]\n",
      " [9.9367166e-01 6.3282982e-03]\n",
      " [9.7643584e-01 2.3564160e-02]\n",
      " [5.5782136e-02 9.4421786e-01]\n",
      " [9.9997401e-01 2.6028225e-05]\n",
      " [9.9691582e-01 3.0841804e-03]\n",
      " [9.9997723e-01 2.2780285e-05]\n",
      " [2.4457675e-04 9.9975544e-01]\n",
      " [9.9995255e-01 4.7404810e-05]\n",
      " [9.9997544e-01 2.4524503e-05]\n",
      " [1.3943531e-03 9.9860567e-01]\n",
      " [8.4487343e-04 9.9915516e-01]\n",
      " [9.9992609e-01 7.3874980e-05]\n",
      " [6.9764572e-01 3.0235428e-01]\n",
      " [4.5023903e-02 9.5497602e-01]\n",
      " [9.9989808e-01 1.0191632e-04]\n",
      " [9.9922729e-01 7.7272375e-04]\n",
      " [9.9986446e-01 1.3553216e-04]\n",
      " [9.8832333e-01 1.1676682e-02]\n",
      " [9.9997795e-01 2.2096739e-05]\n",
      " [9.9995506e-01 4.4901433e-05]\n",
      " [9.7082034e-02 9.0291798e-01]\n",
      " [9.9795592e-01 2.0441029e-03]\n",
      " [9.9855262e-01 1.4474094e-03]\n",
      " [5.8941913e-01 4.1058090e-01]\n",
      " [2.1065187e-01 7.8934813e-01]\n",
      " [9.9933499e-01 6.6498609e-04]]\n"
     ]
    }
   ],
   "source": [
    "for batch in val_loader:\n",
    "    break  # here be your training code\n",
    "print(\"Sample batch:\", batch)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted = model(\n",
    "        input_ids=batch[\"input_ids\"],\n",
    "        attention_mask=batch[\"attention_mask\"],\n",
    "        token_type_ids=batch[\"token_type_ids\"],\n",
    "    )\n",
    "\n",
    "print(\"\\nPrediction (probs):\", torch.softmax(predicted.logits, dim=1).data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoxHzxn0DQqO"
   },
   "source": [
    "**Task 1 (1 point)**\n",
    "\n",
    "- Measure the validation accuracy of your model. Doing so naively may take several hours. Please make sure you use the following optimizations:\n",
    "  - Run the model on GPU with no_grad\n",
    "  - Using batch size larger than 1\n",
    "  - Use optimize data loader with num_workers > 1\n",
    "  - (Optional) Use [mixed precision](https://pytorch.org/docs/stable/notes/amp_examples.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9k5EK7-KA5F2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1264/1264 [02:27<00:00,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'token_type_ids': batch['token_type_ids'].to(device)\n",
    "        }\n",
    "        \n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += predictions.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0R2z_-FZU3qy"
   },
   "outputs": [],
   "source": [
    "assert 0.89 < accuracy < 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KONQ1E0J-y6B"
   },
   "source": [
    "### Training (4 points)\n",
    "\n",
    "For this task, you have two options:\n",
    "\n",
    "__Option A:__ fine-tune your own model. You are free to choose any model __except for the original BERT.__ We recommend [DeBERTa-v3](https://huggingface.co/microsoft/deberta-v3-base). Better yet, choose the best model based on public benchmarks (e.g. [GLUE](https://gluebenchmark.com/)).\n",
    "\n",
    "You can write the training code manually or use transformers.Trainer (see [this example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification)). Please make sure that your model's accuracy is at least __comparable__ with the above example for BERT.\n",
    "\n",
    "\n",
    "__Option B:__ compare at least 3 pre-finetuned models (in addition to the above BERT model). For each model, report (1) its accuracy, (2) its speed, measured in samples per second in your hardware setup and (3) its size in megabytes. Please take care to compare models in equal setting, e.g. same CPU / GPU. Compile your results into a table and write a short (~half-page on top of a table) report, summarizing your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHsPQwHUR3z7"
   },
   "source": [
    "**Task 2 (4 points)**\n",
    "- Choose Option A or Option B (only one will be graded)\n",
    "- Follow all the instructions and restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0ZkZTkl_yMU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./berta_V3 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map:   0%|          | 1000/363846 [00:00<00:43, 8307.12 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   1%|          | 3000/363846 [00:00<00:58, 6214.67 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   2%|▏         | 9000/363846 [00:01<00:41, 8649.13 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   4%|▍         | 14000/363846 [00:01<00:41, 8408.31 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   4%|▍         | 16000/363846 [00:01<00:40, 8537.04 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   8%|▊         | 28000/363846 [00:03<00:38, 8782.88 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   9%|▊         | 31000/363846 [00:03<00:38, 8685.63 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  10%|▉         | 36000/363846 [00:04<00:36, 9104.41 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  12%|█▏        | 43000/363846 [00:05<00:36, 8883.36 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  14%|█▎        | 50000/363846 [00:05<00:35, 8923.72 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  15%|█▍        | 53000/363846 [00:06<00:35, 8831.81 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  17%|█▋        | 62000/363846 [00:07<00:32, 9189.89 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  17%|█▋        | 63000/363846 [00:07<00:33, 9029.80 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  18%|█▊        | 65000/363846 [00:07<00:33, 8914.20 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  19%|█▊        | 68000/363846 [00:07<00:33, 8816.82 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  20%|█▉        | 71000/363846 [00:08<00:32, 9073.43 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  22%|██▏       | 79000/363846 [00:09<00:31, 9013.61 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  23%|██▎       | 84000/363846 [00:09<00:31, 8851.95 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  25%|██▍       | 90000/363846 [00:10<00:30, 9083.38 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  28%|██▊       | 102000/363846 [00:11<00:29, 8885.34 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  29%|██▉       | 105000/363846 [00:12<00:28, 8998.23 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  32%|███▏      | 115000/363846 [00:13<00:30, 8245.85 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  33%|███▎      | 120000/363846 [00:13<00:29, 8149.18 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  34%|███▍      | 124000/363846 [00:14<00:32, 7305.39 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  34%|███▍      | 125000/363846 [00:14<00:31, 7627.02 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  35%|███▍      | 127000/363846 [00:14<00:28, 8182.50 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  35%|███▌      | 128000/363846 [00:14<00:28, 8334.84 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  36%|███▌      | 130000/363846 [00:15<00:28, 8181.77 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  37%|███▋      | 133000/363846 [00:15<00:27, 8466.31 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  37%|███▋      | 135000/363846 [00:15<00:26, 8672.66 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  37%|███▋      | 136000/363846 [00:15<00:25, 8780.62 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  38%|███▊      | 138000/363846 [00:16<00:25, 8992.25 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  38%|███▊      | 139000/363846 [00:16<00:24, 8998.27 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  38%|███▊      | 140000/363846 [00:16<00:25, 8900.23 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  41%|████      | 150000/363846 [00:17<00:23, 8954.34 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  42%|████▏     | 153000/363846 [00:17<00:23, 8841.99 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  43%|████▎     | 155000/363846 [00:17<00:25, 8338.18 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  45%|████▍     | 163000/363846 [00:18<00:22, 8926.53 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  45%|████▌     | 164000/363846 [00:18<00:22, 8872.47 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  46%|████▌     | 167000/363846 [00:19<00:22, 8847.36 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  49%|████▉     | 179000/363846 [00:20<00:20, 9174.82 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  54%|█████▍    | 196000/363846 [00:22<00:19, 8743.39 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  54%|█████▍    | 197000/363846 [00:22<00:18, 8807.60 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  54%|█████▍    | 198000/363846 [00:22<00:18, 8877.43 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  55%|█████▌    | 201000/363846 [00:23<00:18, 8642.87 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  56%|█████▌    | 202000/363846 [00:23<00:18, 8790.54 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  56%|█████▌    | 204000/363846 [00:23<00:17, 8916.98 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  59%|█████▊    | 213000/363846 [00:24<00:22, 6647.42 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  60%|█████▉    | 217000/363846 [00:25<00:17, 8293.16 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  63%|██████▎   | 229000/363846 [00:26<00:14, 9058.13 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  63%|██████▎   | 230000/363846 [00:26<00:15, 8573.19 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  64%|██████▍   | 232000/363846 [00:26<00:16, 8192.80 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  64%|██████▍   | 233000/363846 [00:26<00:15, 8341.72 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  65%|██████▌   | 238000/363846 [00:27<00:15, 8314.89 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  67%|██████▋   | 242000/363846 [00:27<00:13, 8768.63 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  67%|██████▋   | 243000/363846 [00:28<00:13, 8816.09 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  67%|██████▋   | 244000/363846 [00:28<00:13, 8738.25 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  68%|██████▊   | 247000/363846 [00:28<00:13, 8388.89 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  70%|███████   | 256000/363846 [00:29<00:12, 8437.20 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  71%|███████   | 257000/363846 [00:29<00:12, 8559.65 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  71%|███████   | 258000/363846 [00:29<00:12, 8530.76 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  71%|███████   | 259000/363846 [00:29<00:12, 8507.34 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  73%|███████▎  | 267000/363846 [00:31<00:12, 7844.78 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  74%|███████▍  | 269000/363846 [00:31<00:11, 8112.81 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  74%|███████▍  | 270000/363846 [00:31<00:11, 8047.60 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  75%|███████▌  | 273000/363846 [00:31<00:10, 8282.92 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  76%|███████▌  | 276000/363846 [00:32<00:10, 8248.80 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  76%|███████▌  | 277000/363846 [00:32<00:10, 8260.17 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  78%|███████▊  | 283000/363846 [00:33<00:09, 8417.43 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  78%|███████▊  | 284000/363846 [00:33<00:09, 8230.52 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  78%|███████▊  | 285000/363846 [00:33<00:09, 8099.15 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  81%|████████  | 293000/363846 [00:34<00:08, 8476.92 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  81%|████████▏ | 296000/363846 [00:34<00:07, 8560.65 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  82%|████████▏ | 299000/363846 [00:34<00:07, 8657.46 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  83%|████████▎ | 301000/363846 [00:35<00:07, 8334.47 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  84%|████████▍ | 307000/363846 [00:35<00:06, 8431.88 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  86%|████████▌ | 312000/363846 [00:36<00:06, 8103.18 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  86%|████████▌ | 313000/363846 [00:36<00:06, 8090.89 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  86%|████████▋ | 314000/363846 [00:36<00:06, 8217.37 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  89%|████████▉ | 323000/363846 [00:37<00:04, 8611.47 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  91%|█████████ | 332000/363846 [00:38<00:03, 8165.36 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  92%|█████████▏| 333000/363846 [00:39<00:04, 6275.07 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  92%|█████████▏| 334000/363846 [00:39<00:04, 6791.78 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  92%|█████████▏| 335000/363846 [00:39<00:04, 7099.31 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  94%|█████████▍| 342000/363846 [00:40<00:02, 8801.94 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  94%|█████████▍| 343000/363846 [00:40<00:02, 8539.92 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  95%|█████████▍| 345000/363846 [00:40<00:02, 8312.14 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  95%|█████████▌| 346000/363846 [00:40<00:02, 8380.50 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  96%|█████████▌| 349000/363846 [00:41<00:01, 8621.80 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  97%|█████████▋| 352000/363846 [00:41<00:01, 8473.27 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  99%|█████████▊| 359000/363846 [00:42<00:00, 8624.72 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map: 100%|██████████| 363846/363846 [00:42<00:00, 8493.64 examples/s]\n",
      "Map:   0%|          | 0/40430 [00:00<?, ? examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   7%|▋         | 3000/40430 [00:00<00:04, 8392.97 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  22%|██▏       | 9000/40430 [00:01<00:03, 9159.06 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  30%|██▉       | 12000/40430 [00:01<00:03, 8980.86 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  35%|███▍      | 14000/40430 [00:01<00:02, 8861.56 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  37%|███▋      | 15000/40430 [00:01<00:02, 8882.00 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  79%|███████▉  | 32000/40430 [00:03<00:01, 8266.34 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  92%|█████████▏| 37000/40430 [00:04<00:00, 8425.35 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map: 100%|██████████| 40430/40430 [00:04<00:00, 8517.49 examples/s]\n",
      "Map:   1%|          | 2000/390965 [00:00<00:43, 8853.59 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   3%|▎         | 13000/390965 [00:01<00:42, 8966.07 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   4%|▍         | 16000/390965 [00:01<00:43, 8597.97 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   5%|▌         | 21000/390965 [00:02<00:41, 8922.56 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   6%|▌         | 22000/390965 [00:02<00:41, 8963.68 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   6%|▌         | 23000/390965 [00:02<00:41, 8935.41 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   7%|▋         | 27000/390965 [00:03<00:40, 9022.28 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   7%|▋         | 29000/390965 [00:03<00:39, 9083.10 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  10%|█         | 40000/390965 [00:04<00:43, 8098.91 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  11%|█         | 42000/390965 [00:04<00:42, 8186.81 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  13%|█▎        | 50000/390965 [00:05<00:38, 8822.49 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  13%|█▎        | 51000/390965 [00:05<00:38, 8839.99 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  14%|█▎        | 53000/390965 [00:06<00:37, 8976.91 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  18%|█▊        | 71000/390965 [00:08<00:36, 8800.32 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  21%|██▏       | 84000/390965 [00:09<00:34, 8960.39 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  22%|██▏       | 86000/390965 [00:09<00:33, 9007.51 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  23%|██▎       | 89000/390965 [00:10<00:32, 9156.29 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  23%|██▎       | 91000/390965 [00:10<00:33, 9050.15 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  26%|██▌       | 100000/390965 [00:11<00:32, 9048.14 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  27%|██▋       | 106000/390965 [00:12<00:32, 8794.72 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  28%|██▊       | 111000/390965 [00:12<00:31, 8946.09 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  29%|██▉       | 115000/390965 [00:13<00:30, 8965.43 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  30%|██▉       | 116000/390965 [00:13<00:30, 8971.68 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  30%|██▉       | 117000/390965 [00:13<00:30, 8863.38 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  32%|███▏      | 124000/390965 [00:14<00:31, 8538.65 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  33%|███▎      | 129000/390965 [00:14<00:34, 7562.70 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  34%|███▎      | 131000/390965 [00:15<00:31, 8318.70 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  34%|███▍      | 133000/390965 [00:15<00:30, 8405.37 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  36%|███▋      | 142000/390965 [00:16<00:27, 9068.97 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  37%|███▋      | 145000/390965 [00:16<00:28, 8616.65 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  37%|███▋      | 146000/390965 [00:16<00:28, 8556.71 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  38%|███▊      | 148000/390965 [00:17<00:27, 8799.42 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  38%|███▊      | 150000/390965 [00:17<00:27, 8922.35 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  40%|███▉      | 156000/390965 [00:17<00:26, 8854.73 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  42%|████▏     | 164000/390965 [00:18<00:25, 8922.65 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  43%|████▎     | 169000/390965 [00:19<00:25, 8634.26 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  44%|████▍     | 172000/390965 [00:19<00:24, 8833.14 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  45%|████▍     | 174000/390965 [00:19<00:24, 8881.36 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  45%|████▍     | 175000/390965 [00:20<00:24, 8640.13 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  46%|████▌     | 179000/390965 [00:20<00:23, 8965.03 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  47%|████▋     | 185000/390965 [00:21<00:22, 8962.90 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  48%|████▊     | 189000/390965 [00:21<00:24, 8405.97 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  50%|████▉     | 194000/390965 [00:22<00:21, 9084.37 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  51%|█████     | 199000/390965 [00:22<00:21, 8938.71 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  51%|█████     | 200000/390965 [00:22<00:21, 8969.84 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  52%|█████▏    | 204000/390965 [00:23<00:20, 8984.42 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  53%|█████▎    | 207000/390965 [00:23<00:20, 8923.80 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  53%|█████▎    | 208000/390965 [00:23<00:20, 8988.29 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  53%|█████▎    | 209000/390965 [00:23<00:20, 8920.97 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  54%|█████▎    | 210000/390965 [00:24<00:21, 8465.22 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  56%|█████▌    | 218000/390965 [00:24<00:20, 8629.09 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  57%|█████▋    | 222000/390965 [00:25<00:18, 8947.43 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  59%|█████▉    | 231000/390965 [00:26<00:18, 8484.80 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  60%|█████▉    | 233000/390965 [00:26<00:18, 8392.81 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  61%|██████    | 237000/390965 [00:27<00:17, 8846.32 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  63%|██████▎   | 246000/390965 [00:28<00:17, 8318.88 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  65%|██████▍   | 253000/390965 [00:29<00:16, 8270.40 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  66%|██████▌   | 258000/390965 [00:29<00:15, 8596.93 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  68%|██████▊   | 265000/390965 [00:30<00:14, 8741.13 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  69%|██████▊   | 268000/390965 [00:30<00:13, 8830.83 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  70%|██████▉   | 272000/390965 [00:31<00:13, 8979.66 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  74%|███████▍  | 291000/390965 [00:33<00:11, 8734.56 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  76%|███████▌  | 297000/390965 [00:34<00:10, 9090.41 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  76%|███████▌  | 298000/390965 [00:34<00:10, 8835.59 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  78%|███████▊  | 304000/390965 [00:34<00:09, 8743.02 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  78%|███████▊  | 305000/390965 [00:35<00:10, 8367.13 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  78%|███████▊  | 306000/390965 [00:35<00:10, 8009.64 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  81%|████████  | 317000/390965 [00:36<00:08, 8670.31 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  88%|████████▊ | 344000/390965 [00:39<00:05, 8550.49 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  95%|█████████▍| 370000/390965 [00:42<00:02, 8876.09 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  96%|█████████▋| 377000/390965 [00:43<00:01, 9168.96 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  97%|█████████▋| 380000/390965 [00:43<00:01, 8765.06 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  98%|█████████▊| 384000/390965 [00:44<00:00, 8729.29 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map: 100%|██████████| 390965/390965 [00:45<00:00, 8684.22 examples/s]\n",
      "Downloading builder script: 4.20kB [00:00, 4.83MB/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     predictions = np.argmax(predictions, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m metric.compute(predictions=predictions, references=labels)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./results_deberta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mno\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m train_subset = encoded_dataset[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m].shuffle(seed=\u001b[32m42\u001b[39m).select(\u001b[38;5;28mrange\u001b[39m(\u001b[32m10000\u001b[39m))\n\u001b[32m     38\u001b[39m eval_subset = encoded_dataset[\u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m].shuffle(seed=\u001b[32m42\u001b[39m).select(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1000\u001b[39m))\n",
      "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DebertaV2Tokenizer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "model_path = \"./berta_V3\"\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text1\"], examples[\"text2\"], truncation=True, max_length=128)\n",
    "encoded_dataset = qqp.map(preprocess_function, batched=True)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_deberta\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "train_subset = encoded_dataset[\"train\"].shuffle(seed=42).select(range(10000))\n",
    "eval_subset = encoded_dataset[\"validation\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=eval_subset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQD0IV44LrSs"
   },
   "source": [
    "### Finding Duplicates (1 point)\n",
    "\n",
    "Finally, it is time to use your model to find duplicate questions.\n",
    "Please implement a function that takes a question and finds top-5 potential duplicates in the training set. For now, it is fine if your function is slow, as long as it yields correct results.\n",
    "\n",
    "Showcase how your function works with at least 5 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM5WXW8hSl7H"
   },
   "source": [
    "**Task 3 (1 point)**\n",
    "- Implement function for finding duplicates\n",
    "- Test it on several examples (at least 5)\n",
    "- Check suggested duplicates and make a conclusion about model correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLSjmsKaUyQb"
   },
   "outputs": [],
   "source": [
    "<A whole lot of YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2RIdHp6TaZY"
   },
   "source": [
    "### Bonus: Finding Duplicates Faster (0.5 point)\n",
    "\n",
    "Try to find a way to run the function faster than just passing over all questions in a loop. For isntance, you can form a short-list of potential candidates using a cheaper method, and then run your tranformer on that short list. If you opted for this solution, please keep both the original implementation and the optimized one - and explain briefly what is the difference there.\n",
    "\n",
    "**Bonus Task 1 (0.5 point)**\n",
    "- Speed up your implementation from \"Finding Duplicates\" part\n",
    "- Capture both old and new implementation work time\n",
    "- Describe your approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V49F_ZyaUTSx"
   },
   "outputs": [],
   "source": [
    "<A whole lot of YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzJFS5v5UTtz"
   },
   "source": [
    "### Bonus: Finding Duplicates in Old-Fashioned way (1.5 points)\n",
    "\n",
    "In this bonus task you are supposed to use pretrained embeddings (word2vec, GloVe or fasttext) for solving the duplicates problem.\n",
    "\n",
    "**Bonus Task 2 (1.5 points)**\n",
    "- Solve Finding Duplicates problem using mentioned embeddings\n",
    "- Compare old-fashioned solution to previous ones (quality, speed, etc.)\n",
    "- Make a small report (up to 5 steps, results and conclusions) on work done in this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2HjQwr_Vvu6"
   },
   "outputs": [],
   "source": [
    "<A whole lot of YOUR CODE HERE>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
